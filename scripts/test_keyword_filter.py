#!/usr/bin/env python3
"""
æµ‹è¯•å…³é”®è¯è¿‡æ»¤å™¨
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.sources.crawlers.keyword_filter import KeywordFilter, create_filter_from_string


def test_basic_filtering():
    """æµ‹è¯•åŸºæœ¬è¿‡æ»¤åŠŸèƒ½"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•1: åŸºæœ¬è¿‡æ»¤åŠŸèƒ½")
    print("=" * 80)
    print()

    # åˆ›å»ºè¿‡æ»¤å™¨: å¿…é¡»æœ‰"åç«¯", ä¸èƒ½æœ‰"å‰ç«¯", å¯é€‰"Python"
    filter1 = KeywordFilter(["Python", "+åç«¯", "!å‰ç«¯"])
    print(f"è¿‡æ»¤å™¨: {filter1}")
    print()

    test_cases = [
        ("Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆ", True, "æœ‰Pythonå’Œåç«¯ï¼Œæ— å‰ç«¯"),
        ("å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ", False, "æœ‰æ’é™¤è¯'å‰ç«¯'"),
        ("Javaåç«¯å·¥ç¨‹å¸ˆ", True, "æœ‰å¿…é¡»è¯'åç«¯'ï¼Œè™½ç„¶æ— Python"),
        ("å…¨æ ˆå·¥ç¨‹å¸ˆ", False, "ç¼ºå°‘å¿…é¡»è¯'åç«¯'"),
        ("åç«¯æ¶æ„å¸ˆ", True, "æœ‰å¿…é¡»è¯'åç«¯'"),
    ]

    for text, expected, reason in test_cases:
        result = filter1.matches(text)
        status = "âœ…" if result == expected else "âŒ"
        print(f"{status} \"{text}\" => {result} ({reason})")

    print()


def test_scoring():
    """æµ‹è¯•è¯„åˆ†åŠŸèƒ½"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•2: è¯„åˆ†åŠŸèƒ½")
    print("=" * 80)
    print()

    filter2 = KeywordFilter(["Python", "Django", "+åç«¯", "!å‰ç«¯"])
    print(f"è¿‡æ»¤å™¨: {filter2}")
    print()

    test_texts = [
        "Python Djangoåç«¯å¼€å‘",
        "Pythonåç«¯å·¥ç¨‹å¸ˆ",
        "åç«¯æ¶æ„å¸ˆ",
        "Djangoå¼€å‘å·¥ç¨‹å¸ˆ",  # ç¼ºå°‘"åç«¯"ï¼Œåº”è¯¥å¾—0åˆ†
    ]

    for text in test_texts:
        score = filter2.calculate_score(text)
        print(f"åˆ†æ•° {score:5.1f}: {text}")

    print()


def test_string_parsing():
    """æµ‹è¯•å­—ç¬¦ä¸²è§£æ"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•3: å­—ç¬¦ä¸²è§£æ")
    print("=" * 80)
    print()

    test_string = "Python +åç«¯ !å‰ç«¯ Django,Flask"
    print(f"è¾“å…¥å­—ç¬¦ä¸²: \"{test_string}\"")
    print()

    filter3 = create_filter_from_string(test_string)
    print(f"è§£æç»“æœ: {filter3}")
    print()

    print(f"æ™®é€šå…³é”®è¯: {filter3.normal_keywords}")
    print(f"å¿…é¡»å…³é”®è¯: {filter3.required_keywords}")
    print(f"æ’é™¤å…³é”®è¯: {filter3.exclude_keywords}")
    print()


def test_filter_items():
    """æµ‹è¯•æ‰¹é‡è¿‡æ»¤å’Œæ’åº"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•4: æ‰¹é‡è¿‡æ»¤å’Œæ’åº")
    print("=" * 80)
    print()

    items = [
        {"title": "Pythonåç«¯å¼€å‘å·¥ç¨‹å¸ˆ - å­—èŠ‚è·³åŠ¨", "url": "http://example.com/1"},
        {"title": "å‰ç«¯Reactå·¥ç¨‹å¸ˆ", "url": "http://example.com/2"},
        {"title": "Python Djangoåç«¯æ¶æ„å¸ˆ", "url": "http://example.com/3"},
        {"title": "Javaåç«¯å¼€å‘", "url": "http://example.com/4"},
        {"title": "å…¨æ ˆå·¥ç¨‹å¸ˆ", "url": "http://example.com/5"},
        {"title": "åç«¯æŠ€æœ¯ä¸“å®¶ Python", "url": "http://example.com/6"},
    ]

    filter4 = KeywordFilter(["Python", "+åç«¯", "!å‰ç«¯"])
    print(f"è¿‡æ»¤å™¨: {filter4}")
    print(f"åŸå§‹æ•°æ®: {len(items)} æ¡")
    print()

    filtered = filter4.filter_items(items, text_field='title')
    print(f"è¿‡æ»¤å: {len(filtered)} æ¡")
    print()

    print("ç»“æœï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰:")
    for i, item in enumerate(filtered, 1):
        score = item.get('relevance_score', 0)
        title = item.get('title', '')
        print(f"{i}. [{score:5.1f}åˆ†] {title}")

    print()


def test_llm_domain():
    """æµ‹è¯•LLMé¢†åŸŸè¿‡æ»¤"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•5: LLMé¢†åŸŸè¿‡æ»¤")
    print("=" * 80)
    print()

    # LLMé¢†åŸŸï¼šå¿…é¡»æœ‰AIç›¸å…³ï¼Œæ’é™¤ç¡¬ä»¶
    filter5 = KeywordFilter(["LLM", "GPT", "ChatGPT", "+AI", "!GPU", "!èŠ¯ç‰‡"])
    print(f"è¿‡æ»¤å™¨: {filter5}")
    print()

    test_items = [
        {"title": "TikTok å°†å¼€æ”¾ç”¨æˆ·è®¾ç½®ï¼Œå‡å°‘çŸ­è§†é¢‘ä¿¡æ¯æµä¸­çš„ AI å†…å®¹"},
        {"title": "è°·æ­Œå­¦æœ¯æµ‹è¯•æ–°æŠ€èƒ½ï¼šAI æä¾›è®ºæ–‡æ‘˜è¦"},
        {"title": "ç¾¤è”æ¨å‡º PCIe 5.0 ä¼ä¸šçº§ SSD æ–°å“ï¼Œæ ¸æ˜¾ AI æ¨ç†åŠ é€Ÿæ–¹æ¡ˆ"},  # è™½ç„¶æœ‰AIï¼Œä½†ä¹Ÿæœ‰"èŠ¯ç‰‡"ç›¸å…³å†…å®¹
        {"title": "OpenAI å‘å¸ƒ GPT-5 æ¨¡å‹ï¼Œæ€§èƒ½å¤§å¹…æå‡"},
        {"title": "NVIDIA å‘å¸ƒæ–°ä¸€ä»£ GPU èŠ¯ç‰‡"},  # æœ‰æ’é™¤è¯"GPU"å’Œ"èŠ¯ç‰‡"
    ]

    filtered = filter5.filter_items(test_items, text_field='title')
    print(f"è¿‡æ»¤ç»“æœ: {len(filtered)}/{len(test_items)} æ¡")
    print()

    for i, item in enumerate(filtered, 1):
        score = item.get('relevance_score', 0)
        title = item.get('title', '')
        print(f"{i}. [{score:5.1f}åˆ†] {title}")

    print()


def test_empty_filter():
    """æµ‹è¯•ç©ºè¿‡æ»¤å™¨"""
    print("=" * 80)
    print("ğŸ§ª æµ‹è¯•6: ç©ºè¿‡æ»¤å™¨")
    print("=" * 80)
    print()

    filter6 = KeywordFilter([])
    print(f"è¿‡æ»¤å™¨: {filter6}")
    print(f"æ˜¯å¦ä¸ºç©º: {filter6.is_empty}")
    print()

    # ç©ºè¿‡æ»¤å™¨åº”è¯¥åŒ¹é…æ‰€æœ‰å†…å®¹ï¼ˆæ²¡æœ‰ä»»ä½•é™åˆ¶ï¼‰
    test_texts = ["ä»»æ„æ–‡æœ¬", "Another text", "123"]
    for text in test_texts:
        result = filter6.matches(text)
        print(f"åŒ¹é… \"{text}\": {result}")

    print()


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    test_basic_filtering()
    test_scoring()
    test_string_parsing()
    test_filter_items()
    test_llm_domain()
    test_empty_filter()

    print("=" * 80)
    print("âœ¨ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)
    print()
    print("ğŸ’¡ å…³é”®è¯è¿‡æ»¤è¯­æ³•:")
    print("   - normal_word: æ™®é€šå…³é”®è¯ï¼ˆå¯é€‰ï¼Œå¢åŠ ç›¸å…³æ€§åˆ†æ•°ï¼‰")
    print("   - +required_word: å¿…é¡»åŒ…å«çš„å…³é”®è¯")
    print("   - !exclude_word: å¿…é¡»æ’é™¤çš„å…³é”®è¯")
    print()
    print("ğŸ’¡ è¯„åˆ†è§„åˆ™:")
    print("   - åŸºç¡€åˆ†: 10åˆ†")
    print("   - æ¯ä¸ªå¿…é¡»å…³é”®è¯: +20åˆ†")
    print("   - æ¯ä¸ªæ™®é€šå…³é”®è¯: +10åˆ†")
    print("   - æœ€é«˜åˆ†: 100åˆ†")
    print()


if __name__ == "__main__":
    run_all_tests()
